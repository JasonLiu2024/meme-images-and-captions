{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10cd0a710>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib as imp\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for each of the 300 images, Train & Validate uses 2850 captions (out of 3000)\n"
     ]
    }
   ],
   "source": [
    "import data\n",
    "imp.reload(data)\n",
    "manager = data.Meme_n_Caption_Data_Manager(\n",
    "    FILENAME_all_image_embeddings='image_embeddings.pt',\n",
    "    FILENAME_all_caption_embeddings='caption_embeddings.pt',\n",
    "    FILENAME_MAP_image_index_TO_caption_indices='image_index_TO_caption_index.npy'\n",
    ")\n",
    "all_indices = list(range(len(manager.MAP_image_index_TO_caption_indices[0])))\n",
    "np.random.shuffle(all_indices)\n",
    "train_ratio, validate_ratio, test_ratio = 0.7, 0.1, 0.2 # 0.7, 0.1, 0.2\n",
    "# assert train_ratio + validate_ratio + test_ratio == 1, \"STOP! Train/Validate/Test split NO add to 1\"\n",
    "test_indices = np.asarray(all_indices[int(len(all_indices) * (1 - test_ratio)):])\n",
    "train_and_validate_indices = np.asarray(all_indices[:int(len(all_indices) * (1 - test_ratio))])\n",
    "# assert len(train_and_validate_indices) + len(test_indices) == len(all_indices), \"STOP! T/V/T indices split wrong\"\n",
    "print(f\"for each of the 300 images, Train & Validate uses {len(train_and_validate_indices)} captions (out of {len(all_indices)})\")\n",
    "# train_indices = all_indices[:int(len(all_indices) * (train_ratio))]\n",
    "# validate_indices = all_indices[int(len(all_indices) * (train_ratio)):int(len(all_indices) * (1 - test_ratio))]\n",
    "# assert len(train_indices) + len(validate_indices) + len(test_indices) == len(all_indices), \"STOP! T/V/T indices split wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "imp.reload(model)\n",
    "imp.reload(data)\n",
    "\n",
    "def cross_validate(m: nn.Module, hyperparameters,\n",
    "        plot: bool=False):\n",
    "    DOER_CV = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    for train_indicesCEPTION, validate_indicesCEPTION in DOER_CV.split(\n",
    "        np.asarray(train_and_validate_indices)[:, None], train_and_validate_indices):\n",
    "        train_losses = model.train(model=m, \n",
    "            dataloader_train=manager.get_dataloader(\n",
    "                batch_size=hyperparameters['batch_size'], \n",
    "                RATIO_negative_samples_over_positive_samples=hyperparameters['ratio_-_samples_count_over_+_samples_count'], \n",
    "                INDICES_usable_captions=train_and_validate_indices[train_indicesCEPTION]), hyperparameters=hyperparameters)\n",
    "        print(train_losses[0:10])\n",
    "        if plot:\n",
    "            f, ax = plt.subplots(figsize=(4, 4))\n",
    "            ax.plot(train_losses)\n",
    "        # break\n",
    "    # inference\n",
    "    test_losses, test_accuracy, aurocs, auprcs = model.test(model=m, \n",
    "        dataloader_test=manager.get_dataloader(\n",
    "            batch_size=hyperparameters['batch_size'], \n",
    "            RATIO_negative_samples_over_positive_samples=hyperparameters['ratio_-_samples_count_over_+_samples_count'], \n",
    "            INDICES_usable_captions=test_indices),\n",
    "        hyperparameters=hyperparameters\n",
    "        )\n",
    "    auroc_mean, auroc_std = np.asarray(aurocs).mean(), np.asarray(aurocs).std()\n",
    "    auprc_mean, auprc_std = np.asarray(auprcs).mean(), np.asarray(auprcs).std()\n",
    "    losses_mean, losses_std = np.asarray(test_losses).mean(), np.asarray(test_losses).std()\n",
    "    # print(m)\n",
    "    print(f\"Test AUROC: {auroc_mean, auroc_std}\")\n",
    "    print(f\"Test AUPRC: {auprc_mean, auprc_std}\")\n",
    "    print(f\"Test Loss: {losses_mean, losses_std}\")\n",
    "    print(f\"Test Accuracy: %{test_accuracy}\")\n",
    "    return m\n",
    "\n",
    "hyperparameters = {'learning_rate': 1e-3, 'batch_size': 64, \n",
    "    'optimizer_type': torch.optim.Adam, 'ratio_-_samples_count_over_+_samples_count': 1.0,\n",
    "    'loss_function': nn.BCELoss}\n",
    "m = cross_validate(model.Siamese(), hyperparameters,\n",
    "    plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
